{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from string import ascii_uppercase\n",
    "import math\n",
    "import time\n",
    "from swalign import swalign\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "import random\n",
    "import operator\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# ****** functions ********\n",
    "\n",
    "#read n .fna database files in the specified path\n",
    "#set n = 0 to read all files\n",
    "def ReadDataBase(_path, n):\n",
    "    seqList = []\n",
    "    from os import path\n",
    "    files = os.listdir(_path) #makes a list of all files in folder\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for f in files:\n",
    "        for seq_record in SeqIO.parse(_path + f, \"fasta\"): \n",
    "            seqList.append(seq_record.seq) # reads each file into a list\n",
    "            j += 1\n",
    "            if(n > 0):\n",
    "                if(j > n-1):\n",
    "                    i = n\n",
    "                    break\n",
    "        i += 1\n",
    "        j = 0\n",
    "        \n",
    "        if(n > 0):\n",
    "            if(i > n-1):\n",
    "                break\n",
    "                \n",
    "    return seqList               \n",
    "\n",
    "#creates dictionary with all permutations of length n \n",
    "#with repetition to index Feature Vector\n",
    "def CreateDictionary(n):\n",
    "    chars = \"ACGT\"\n",
    "    arr = list(itertools.product(chars, repeat=n))\n",
    "    \n",
    "    D = {}\n",
    "    i = 0\n",
    "\n",
    "    for a in arr:\n",
    "        D[''.join(a)] = i\n",
    "        i += 1\n",
    "        \n",
    "    return D\n",
    "\n",
    "#builds the feature vector for sequence using specified indexing dictionary\n",
    "def FeatureVector(dictionary, sequence, n):    \n",
    "    sLen = len(sequence)\n",
    "    arr = [0]*4**n\n",
    "    i = 0\n",
    "    \n",
    "    while(1):\n",
    "        w = sequence[i:i+n]\n",
    "        try:\n",
    "            arr[D[w]] += 1\n",
    "        except:\n",
    "            i = i\n",
    "        i += 1\n",
    "        if(i+n > sLen):\n",
    "            break\n",
    "    \n",
    "    return arr\n",
    "\n",
    "#Reads the DB files and puts the information of the file in a array of strings\n",
    "def readfile(filename):\n",
    "    temp = open(filename, 'r').read().split('\\n')\n",
    "    return temp\n",
    "    \n",
    "    \n",
    "#returns a random string of specified length\n",
    "#length: strign length\n",
    "def randomword(length):\n",
    "    return (''.join(choice('ACGT') for i in range(0, length)))\n",
    "\n",
    "#retuns an array of random strings\n",
    "#size: how many strings there will be in the array\n",
    "#lakeMinLen: min sequence length\n",
    "#lakeMaxLen: max sequence length\n",
    "def lakeString(size, lakeMinLen, lakeMaxLen):     \n",
    "    lake_water = []\n",
    "    for i in range(0, size):\n",
    "        random.seed()\n",
    "        #generates a random sequence length\n",
    "        y = random.randint(lakeMinLen, lakeMaxLen)\n",
    "        \n",
    "        _str = randomword(y)\n",
    "        lake_water.append(_str)\n",
    "    return lake_water\n",
    "\n",
    "# ******************************************************* main ****************************************************\n",
    "print(\"reading viruses...\")\n",
    "known_viruses = ReadDataBase(\"../database/virus/\", 50)\n",
    "print(\"reading bacterias...\")\n",
    "known_bacterias = ReadDataBase(\"../database/bact/\", 50)\n",
    "print(\"reading lake samples...\")\n",
    "lake = ReadDataBase(\"../database/lake/\", 50)\n",
    "print(\"finished reading data\")\n",
    "\n",
    "#matrix with all feature vectors\n",
    "n = 4\n",
    "D = CreateDictionary(n)\n",
    "matrix = []\n",
    "\n",
    "print(\"lake: \", len(lake))\n",
    "for w in lake:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    matrix.append(arr)\n",
    "\n",
    "print(\"vir: \", len(known_viruses))\n",
    "for w in known_viruses:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    matrix.append(arr)\n",
    "\n",
    "print(\"bact: \", len(known_bacterias))\n",
    "for w in known_bacterias:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    matrix.append(arr)\n",
    "    \n",
    "\n",
    "    \n",
    "#### PCA\n",
    "pca_components = 3\n",
    "X = np.array(matrix)\n",
    "# input: samples x features\n",
    "pca = PCA(n_components=pca_components)\n",
    "Xhat = pca.fit_transform(X)\n",
    "print(\"Percentage of represented variance: \", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# print(len(matrix))\n",
    "# len_lake = len(lake)\n",
    "# len_viruses = len(known_viruses)\n",
    "# data = np.transpose(Xhat)\n",
    "# data1 = data[:, :len_lake]\n",
    "# data2 = data[:, len_lake:(len_lake+len_viruses)]\n",
    "# data3 = data[:, (len_lake+len_viruses):]\n",
    "\n",
    "# # data1 = data[:, :len_viruses]\n",
    "# # data2 = data[:, len_viruses:]\n",
    "# # data3 = data[:, len_viruses:]\n",
    "\n",
    "# print(data1.shape)\n",
    "# print(data2.shape)\n",
    "# print(data3.shape)\n",
    "\n",
    "# ####### Plot results\n",
    "# if pca_components == 2:\n",
    "    # plt.plot(data1[0], data1[1], 'go')\n",
    "    # plt.plot(data2[0], data2[1], 'ro')\n",
    "    # plt.plot(data3[0], data3[1], 'bo')\n",
    "# elif pca_components == 3:\n",
    "    # fig = plt.figure()\n",
    "    # ax = fig.add_subplot(111, projection='3d')\n",
    "    # ax.scatter(data1[0], data1[1], data1[2], c='g', depthshade=False)\n",
    "    # ax.scatter(data2[0], data2[1], data2[2], c='r', depthshade=False)\n",
    "    # ax.scatter(data3[0], data3[1], data3[2], c='b', depthshade=False)\n",
    "    \n",
    "# plt.show()\n",
    "\n",
    "\n",
    "#### K MEANS CLUSTERING\n",
    "data = np.array(Xhat)\n",
    "\n",
    "len_lake = len(lake)\n",
    "len_viruses = len(known_viruses)\n",
    "\n",
    "data_in = data[len_lake:,:]\n",
    "estimator =  KMeans(n_clusters=2)\n",
    "estimator.fit(data_in)\n",
    "labels = estimator.labels_\n",
    "\n",
    "print(labels)\n",
    "data_in_trans = np.transpose(data_in)\n",
    "\n",
    "a = 0\n",
    "b = 0\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(len(data_in)):\n",
    "    if i < len_viruses:\n",
    "        a += 1\n",
    "        if labels[i] == 0:\n",
    "            ax.scatter(data_in_trans[0,i], data_in_trans[1,i], data_in_trans[2,i], c='y', marker='o', depthshade=False)\n",
    "        elif labels[i] == 1:\n",
    "            ax.scatter(data_in_trans[0,i], data_in_trans[1,i], data_in_trans[2,i], c='y', marker='^', depthshade=False)\n",
    "    elif i >= len_viruses:\n",
    "        b += 1\n",
    "        if labels[i] == 0:\n",
    "            ax.scatter(data_in_trans[0,i], data_in_trans[1,i], data_in_trans[2,i], c='b', marker='o', depthshade=False)\n",
    "        elif labels[i] == 1:\n",
    "            ax.scatter(data_in_trans[0,i], data_in_trans[1,i], data_in_trans[2,i], c='b', marker='^', depthshade=False)\n",
    "\n",
    "# len_lake = len(lake)\n",
    "# len_viruses = len(known_viruses)\n",
    "# data1 = data_in_trans[:, :len_lake]\n",
    "# data2 = data_in_trans[:, len_lake:(len_lake+len_viruses)]\n",
    "# data3 = data_in_trans[:, (len_lake+len_viruses):]\n",
    "# ax.scatter(data1[0], data1[1], data1[2], c='g', marker = 'o', depthshade=False)\n",
    "# ax.scatter(data2[0], data2[1], data2[2], c='y', marker = 'o', depthshade=False)\n",
    "# ax.scatter(data3[0], data3[1], data3[2], c='b', marker = 'o', depthshade=False)\n",
    "\n",
    "print(len_lake, len_viruses)\n",
    "print(\"a/b: \", a, b)\n",
    "\n",
    "\n",
    "half1 = sum(labels[:len_viruses])\n",
    "half2 = sum(labels[len_viruses:])\n",
    "if half1 > half2:\n",
    "    err = len_viruses - half1 + half2\n",
    "else:\n",
    "    err = len_viruses - half2 + half1\n",
    "print(\"accuracy: \", (100-err), \"%\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
