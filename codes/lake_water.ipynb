{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading lake...\n",
      "(1000,)\n",
      "running knn with  1653  neighbors....\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# Adding this snippet so the code can run on osx\n",
    "from sys import platform as platform_name\n",
    "if platform_name == \"darwin\":\n",
    "   import sys\n",
    "   sys.path.append('//anaconda/lib/python3.5/site-packages/')\n",
    "\n",
    "import random\n",
    "from random import choice\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import numpy as np\n",
    "from numpy import trapz\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import generate_fake_lake as fl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ****** functions ********\n",
    "\n",
    "#read n .fna database files in the specified path\n",
    "#set n = 0 to read all files\n",
    "def ReadDataBaseFilenames(_path, n, filename_filename):\n",
    "    seqList = []\n",
    "    filenameList = []\n",
    "    from os import path\n",
    "    files = os.listdir(_path) #makes a list of all files in folder\n",
    "    i = 0\n",
    "    j = 0\n",
    "    if '.DS_Store' in files:\n",
    "        files.remove('.DS_Store')\n",
    "    for f in files:\n",
    "        for seq_record in SeqIO.parse(_path + f, \"fasta\"):\n",
    "            s = seq_record.seq\n",
    "            seqList.append(s) # reads each file into a list\n",
    "            filenameList.append(_path + f)\n",
    "            j += 1\n",
    "            if(n > 0):\n",
    "                if(j > n-1):\n",
    "                    i = n\n",
    "                    break\n",
    "        i += 1\n",
    "        j = 0\n",
    "\n",
    "        if(n > 0):\n",
    "            if(i > n-1):\n",
    "                break\n",
    "\n",
    "    fid = open(filename_filename, 'w')\n",
    "    for f in filenameList:\n",
    "        fid.write(f + '\\n')\n",
    "    fid.close()\n",
    "    return seqList, filenameList\n",
    "\n",
    "\n",
    "#creates dictionary with all permutations of length n\n",
    "#with repetition to index Feature Vector\n",
    "def CreateDictionary(n):\n",
    "    chars = \"ACGT\"\n",
    "    arr = list(itertools.product(chars, repeat=n))\n",
    "\n",
    "    D = {}\n",
    "    i = 0\n",
    "\n",
    "    for a in arr:\n",
    "        D[''.join(a)] = i\n",
    "        i += 1\n",
    "\n",
    "    return D\n",
    "\n",
    "#builds the feature vector for sequence using specified indexing dictionary\n",
    "def FeatureVector(dictionary, sequence, n):\n",
    "    sLen = len(sequence)\n",
    "    arr = [0]*4**n\n",
    "    i = 0\n",
    "    while(1):\n",
    "        w = sequence[i:i+n]\n",
    "        try:\n",
    "            arr[dictionary[w]] += 1\n",
    "        except:\n",
    "            i = i\n",
    "        i += 1\n",
    "        if(i+n > sLen):\n",
    "            break\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def kdtree(data, lake_matrix, k_neighbors = 10, leaf_size = 20):\n",
    "    # training\n",
    "    # kdtree = KDTree(data, leaf_size=leaf_size, metric='minkowski')\n",
    "    kdtree = KDTree(data, leaf_size=leaf_size, metric='euclidean')\n",
    "\n",
    "    # testing\n",
    "    distances, indices = kdtree.query(lake_matrix, k=k_neighbors)\n",
    "    return np.array(indices), distances\n",
    "\n",
    "def listToString(list):\n",
    "    string = ''\n",
    "    for ll in list:\n",
    "        for l in ll:\n",
    "            string += str(l) + ' '\n",
    "        string += '\\n'\n",
    "    return string\n",
    "\n",
    "def filenameToMatrix(file):\n",
    "    l = []\n",
    "    fid = open(file,'r')\n",
    "    for f in fid:\n",
    "        l.append(f.replace('\\n',''))\n",
    "    return l\n",
    "        \n",
    "def process():    \n",
    "    lake_matrix = []\n",
    "\n",
    "    n = 4; D = CreateDictionary(n)\n",
    "    for w in lake:\n",
    "        arr = FeatureVector(D, str(w), n)\n",
    "        arr = np.divide(np.array(arr), len(w))\n",
    "        lake_matrix.append(arr)\n",
    "    \n",
    "    len_lake = len(lake)\n",
    "    len_viruses = len(virus_matrix)\n",
    "\n",
    "    matrix = np.vstack((virus_matrix,bact_matrix))\n",
    "    virus_bact_filenames = np.hstack((virus_filenames,bact_filenames))\n",
    "    \n",
    "    ###### PCA\n",
    "    if use_pca:\n",
    "        print(\"performing PCA...\")\n",
    "        X = np.array(matrix)\n",
    "        # PCA input: samples x features\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        Xhat = pca.fit_transform(X)\n",
    "        print(\"Percentage of represented variance: \", sum(pca.explained_variance_ratio_))\n",
    "    \n",
    "    ###### CLASSIFICATION\n",
    "    if use_pca:\n",
    "        data = np.array(Xhat)\n",
    "        lake_matrix = pca.transform(lake_matrix)\n",
    "    else:\n",
    "        data = np.array(matrix)\n",
    "    \n",
    "    ### choose a classification method\n",
    "    ## the method will pick the best candidates to perform local alignment in each lake sample\n",
    "    siz1, siz2 = data.shape\n",
    "    neighbors = round(perc*siz1)\n",
    "    print(\"running knn with \", neighbors, \" neighbors....\")\n",
    "    \n",
    "    # classification call\n",
    "    indices, dist = kdtree(data, lake_matrix, k_neighbors = neighbors, leaf_size = 30)\n",
    "    \n",
    "    return indices, dist\n",
    "\n",
    "# ******************************************************* main ****************************************************\n",
    "\n",
    "# to use preprocessed bacteria and virus files\n",
    "use_presaved = True\n",
    "presaved_path = \"../presaved/\"\n",
    "\n",
    "# if not using presaved, enter here where are the .fasta files\n",
    "virus_database_path = \"../database/virus/\"\n",
    "bact_database_path = \"../database/bact/\"\n",
    "\n",
    "lake_path = \"../database/lake/\"\n",
    "lake_quantity = 1000\n",
    "\n",
    "# to reduce dimensionality of the data\n",
    "use_pca = False\n",
    "pca_components = 100\n",
    "\n",
    "# percentage of neighbors to look for\n",
    "perc = .15\n",
    "\n",
    "if use_presaved:\n",
    "    virus_matrix = np.loadtxt(presaved_path + \"virus_features.txt\")\n",
    "    bact_matrix = np.loadtxt(presaved_path + \"bact_features.txt\")\n",
    "    virus_filenames = filenameToMatrix(presaved_path + \"virus_filenames.txt\")\n",
    "    bact_filenames = filenameToMatrix(presaved_path + \"bact_filenames.txt\")\n",
    "else:\n",
    "    print(\"reading data...\")\n",
    "    known_viruses, virus_filenames = ReadDataBaseFilenames(virus_database_path, 0, presaved_path + \"virus_filenames.txt\")\n",
    "    known_bacterias, bact_filenames = ReadDataBaseFilenames(bact_database_path, 0, presaved_path + \"bact_filenames.txt\")\n",
    "    virus_matrix = []\n",
    "    bact_matrix = []\n",
    "    n = 4; D = CreateDictionary(n)\n",
    "    print(\"generating viruses feature vectors...\")\n",
    "    for w in known_viruses:\n",
    "        arr = FeatureVector(D, str(w), n)\n",
    "        arr = np.divide(np.array(arr), len(w))\n",
    "        virus_matrix.append(arr)\n",
    "    m=0\n",
    "    print(\"generating bacterias feature vectors...\")\n",
    "    for w in known_bacterias:\n",
    "        arr = FeatureVector(D, str(w), n)\n",
    "        arr = np.divide(np.array(arr), len(w))\n",
    "        m+=1\n",
    "        bact_matrix.append(arr)\n",
    "    # saving feature vectors in file\n",
    "    fid1 = open(presaved_path + 'virus_features.txt', 'w')\n",
    "    fid2 = open(presaved_path + 'bact_features.txt', 'w')\n",
    "    fid1.write(listToString(virus_matrix))\n",
    "    fid2.write(listToString(bact_matrix))\n",
    "    fid1.close(); fid2.close()\n",
    "\n",
    "\n",
    "print(\"reading lake...\")\n",
    "lake, lake_filenames = ReadDataBaseFilenames(lake_path, lake_quantity, presaved_path + \"lake_filenames.txt\")    \n",
    "print(np.array(lake).shape)\n",
    "\n",
    "indices, dist = process()\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
