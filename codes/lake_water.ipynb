{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading viruses...\n",
      "reading bacterias...\n",
      "reading lake samples...\n",
      "finished reading data\n",
      "lake shape:  (200, 256)\n",
      "virus shape:  (200, 256)\n",
      "bacteria shape:  (200, 256)\n",
      "Percentage of represented variance:  0.399059612641\n",
      "\n",
      "Accuraccy:  0.77\n"
     ]
    }
   ],
   "source": [
    "# Adding this snippet so the code can run on osx\n",
    "from sys import platform as platform_name\n",
    "if platform_name == \"darwin\":  \n",
    "    import sys\n",
    "    sys.path.append('//anaconda/lib/python3.5/site-packages/')\n",
    "    # matplotlib is breaking \n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "from random import choice\n",
    "from string import ascii_uppercase\n",
    "import math\n",
    "import time\n",
    "from swalign import swalign\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "import random\n",
    "import operator\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# ****** functions ********\n",
    "\n",
    "#read n .fna database files in the specified path\n",
    "#set n = 0 to read all files\n",
    "def ReadDataBase(_path, n):\n",
    "    seqList = []\n",
    "    from os import path\n",
    "    files = os.listdir(_path) #makes a list of all files in folder\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for f in files:\n",
    "        for seq_record in SeqIO.parse(_path + f, \"fasta\"): \n",
    "            seqList.append(seq_record.seq) # reads each file into a list\n",
    "            j += 1\n",
    "            if(n > 0):\n",
    "                if(j > n-1):\n",
    "                    i = n\n",
    "                    break\n",
    "        i += 1\n",
    "        j = 0\n",
    "        \n",
    "        if(n > 0):\n",
    "            if(i > n-1):\n",
    "                break\n",
    "                \n",
    "    return seqList               \n",
    "\n",
    "#creates dictionary with all permutations of length n \n",
    "#with repetition to index Feature Vector\n",
    "def CreateDictionary(n):\n",
    "    chars = \"ACGT\"\n",
    "    arr = list(itertools.product(chars, repeat=n))\n",
    "    \n",
    "    D = {}\n",
    "    i = 0\n",
    "\n",
    "    for a in arr:\n",
    "        D[''.join(a)] = i\n",
    "        i += 1\n",
    "        \n",
    "    return D\n",
    "\n",
    "#builds the feature vector for sequence using specified indexing dictionary\n",
    "def FeatureVector(dictionary, sequence, n):    \n",
    "    sLen = len(sequence)\n",
    "    arr = [0]*4**n\n",
    "    i = 0\n",
    "    \n",
    "    while(1):\n",
    "        w = sequence[i:i+n]\n",
    "        try:\n",
    "            arr[D[w]] += 1\n",
    "        except:\n",
    "            i = i\n",
    "        i += 1\n",
    "        if(i+n > sLen):\n",
    "            break\n",
    "    \n",
    "    return arr\n",
    "\n",
    "#Reads the DB files and puts the information of the file in a array of strings\n",
    "def readfile(filename):\n",
    "    temp = open(filename, 'r').read().split('\\n')\n",
    "    return temp\n",
    "    \n",
    "    \n",
    "#returns a random string of specified length\n",
    "#length: strign length\n",
    "def randomword(length):\n",
    "    return (''.join(choice('ACGT') for i in range(0, length)))\n",
    "\n",
    "#retuns an array of random strings\n",
    "#size: how many strings there will be in the array\n",
    "#lakeMinLen: min sequence length\n",
    "#lakeMaxLen: max sequence length\n",
    "def lakeString(size, lakeMinLen, lakeMaxLen):     \n",
    "    lake_water = []\n",
    "    for i in range(0, size):\n",
    "        random.seed()\n",
    "        #generates a random sequence length\n",
    "        y = random.randint(lakeMinLen, lakeMaxLen)\n",
    "        \n",
    "        _str = randomword(y)\n",
    "        lake_water.append(_str)\n",
    "    return lake_water\n",
    "\n",
    "def readTxtFile(filename):\n",
    "    data = []\n",
    "    fid = open(filename,'r')\n",
    "    for line in fid:\n",
    "        data.append(line)\n",
    "    return data\n",
    "        \n",
    "\n",
    "# ******************************************************* main ****************************************************\n",
    "\n",
    "use_pca = True\n",
    "pca_components = 2\n",
    "\n",
    "print(\"reading viruses...\")\n",
    "known_viruses = ReadDataBase(\"../database/virus/\", 200)\n",
    "print(\"reading bacterias...\")\n",
    "known_bacterias = ReadDataBase(\"../database/bact/\", 200)\n",
    "print(\"reading lake samples...\")\n",
    "\n",
    "# lake = ReadDataBase(\"../database/lake/\", 50)\n",
    "lake = readTxtFile(\"../database/lake.txt\") \n",
    "\n",
    "print(\"finished reading data\")\n",
    "\n",
    "#matrix with all feature vectors\n",
    "n = 4\n",
    "D = CreateDictionary(n)\n",
    "lake_matrix = []\n",
    "virus_matrix = []\n",
    "bact_matrix = []\n",
    "\n",
    "for w in lake:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    lake_matrix.append(arr)\n",
    "\n",
    "for w in known_viruses:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    virus_matrix.append(arr)\n",
    "\n",
    "for w in known_bacterias:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    bact_matrix.append(arr)\n",
    "\n",
    "len_lake = len(lake)\n",
    "len_viruses = len(known_viruses)\n",
    "    \n",
    "print(\"lake shape: \", np.matrix(lake_matrix).shape)\n",
    "print(\"virus shape: \", np.matrix(virus_matrix).shape)\n",
    "print(\"bacteria shape: \", np.matrix(bact_matrix).shape)\n",
    "\n",
    "matrix = np.vstack((virus_matrix,bact_matrix))\n",
    "\n",
    "\n",
    "### PCA\n",
    "if use_pca:\n",
    "    X = np.array(matrix)\n",
    "    # PCA input: samples x features\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    Xhat = pca.fit_transform(X)\n",
    "    print(\"Percentage of represented variance: \", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "    data = np.transpose(Xhat)\n",
    "    data_virus = data[:, :len_viruses]\n",
    "    data_bact = data[:,len_viruses:]\n",
    "\n",
    "#     ####### Plot results\n",
    "#     if pca_components == 2:\n",
    "#         plt.plot(data_virus[0], data_virus[1], 'go')\n",
    "#         plt.plot(data_bact[0], data_bact[1], 'ro')\n",
    "#     elif pca_components == 3:\n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "#         ax.scatter(data_virus[0], data_virus[1], data_virus[2], c='g', depthshade=False)\n",
    "#         ax.scatter(data_bact[0], data_bact[1], data_bact[2], c='r', depthshade=False)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#### K MEANS CLUSTERING\n",
    "if use_pca:\n",
    "    data = np.array(Xhat)\n",
    "else:\n",
    "    data = np.array(matrix)\n",
    "    \n",
    "# training\n",
    "estimator = KMeans(n_clusters=12)\n",
    "estimator.fit(data)\n",
    "training_labels = estimator.labels_\n",
    "\n",
    "# testing\n",
    "if use_pca:\n",
    "    lake_matrix = pca.transform(lake_matrix)\n",
    "estimated_labels = estimator.predict(lake_matrix)\n",
    "\n",
    "right = 0\n",
    "cnt_lbl = 0\n",
    "for lbl in estimated_labels:\n",
    "    labels_idx = np.where(training_labels == lbl)[0]\n",
    "    cnt_virus = 0\n",
    "    cnt_bact = 0\n",
    "    for lblidx in labels_idx:\n",
    "        if lblidx < len_viruses:\n",
    "            cnt_virus += 1\n",
    "        else:\n",
    "            cnt_bact += 1\n",
    "    if cnt_virus > cnt_bact and cnt_lbl < 100: # 100 for that sample\n",
    "        right += 1\n",
    "    if cnt_bact > cnt_virus and cnt_lbl >= 100:\n",
    "        right += 1\n",
    "    cnt_lbl += 1\n",
    "\n",
    "print (\"\\nAccuraccy: \", right/len_lake)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_trans = np.transpose(data)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# for i in range(len(data_in)):\n",
    "#     if i < len_viruses:\n",
    "#         if labels[i] == 0:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='y', marker='o', depthshade=False)\n",
    "#         elif labels[i] == 1:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='y', marker='^', depthshade=False)\n",
    "#     elif i >= len_viruses:\n",
    "#         if labels[i] == 0:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='b', marker='o', depthshade=False)\n",
    "#         elif labels[i] == 1:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='b', marker='^', depthshade=False)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('myfig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
