{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading viruses...\n",
      "reading bacterias...\n",
      "reading lake samples...\n",
      "finished reading data\n",
      "feature vector lake...\n",
      "50 of 201\n",
      "100 of 201\n",
      "150 of 201\n",
      "200 of 201\n",
      "feature vector virus...\n",
      "50 of 200\n",
      "100 of 200\n",
      "150 of 200\n",
      "200 of 200\n",
      "feature vector bacteria...\n",
      "50 of 200\n",
      "100 of 200\n",
      "150 of 200\n",
      "200 of 200\n",
      "lake shape:  (201, 256)\n",
      "virus shape:  (200, 256)\n",
      "bacteria shape:  (200, 256)\n",
      "% of virus in cluster  0 :  0.0\n",
      "% of virus in cluster  1 :  1.0\n",
      "% of virus in cluster  2 :  0.30952380952380953\n",
      "% of virus in cluster  3 :  0.44285714285714284\n",
      "% of virus in cluster  4 :  1.0\n",
      "% of virus in cluster  5 :  0.8947368421052632\n",
      "% of virus in cluster  6 :  0.125\n",
      "% of virus in cluster  7 :  0.16981132075471697\n",
      "% of virus in cluster  8 :  0.0\n",
      "% of virus in cluster  9 :  0.8\n",
      "% of virus in cluster  10 :  0.7666666666666667\n",
      "% of virus in cluster  11 :  0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2526ed003d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_pca\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mlake_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlake_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m \u001b[0mestimated_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlake_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster_centers_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES,\n\u001b[0;32m--> 794\u001b[0;31m                         warn_on_dtype=True)\n\u001b[0m\u001b[1;32m    795\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mexpected_n_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Adding this snippet so the code can run on osx\n",
    "from sys import platform as platform_name\n",
    "if platform_name == \"darwin\":  \n",
    "   import sys\n",
    "   sys.path.append('//anaconda/lib/python3.5/site-packages/')\n",
    "#    # matplotlib is breaking \n",
    "#    import matplotlib\n",
    "#    matplotlib.use('Agg')\n",
    "\n",
    "from random import choice\n",
    "from string import ascii_uppercase\n",
    "import math\n",
    "import time\n",
    "from swalign import swalign\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "import random\n",
    "import operator\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# ****** functions ********\n",
    "\n",
    "#read n .fna database files in the specified path\n",
    "#set n = 0 to read all files\n",
    "def ReadDataBase(_path, n):\n",
    "    seqList = []\n",
    "    from os import path\n",
    "    files = os.listdir(_path) #makes a list of all files in folder\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for f in files:\n",
    "        for seq_record in SeqIO.parse(_path + f, \"fasta\"): \n",
    "            seqList.append(seq_record.seq) # reads each file into a list\n",
    "            j += 1\n",
    "            if(n > 0):\n",
    "                if(j > n-1):\n",
    "                    i = n\n",
    "                    break\n",
    "        i += 1\n",
    "        j = 0\n",
    "        \n",
    "        if(n > 0):\n",
    "            if(i > n-1):\n",
    "                break\n",
    "                \n",
    "    return seqList               \n",
    "\n",
    "#creates dictionary with all permutations of length n \n",
    "#with repetition to index Feature Vector\n",
    "def CreateDictionary(n):\n",
    "    chars = \"ACGT\"\n",
    "    arr = list(itertools.product(chars, repeat=n))\n",
    "    \n",
    "    D = {}\n",
    "    i = 0\n",
    "\n",
    "    for a in arr:\n",
    "        D[''.join(a)] = i\n",
    "        i += 1\n",
    "        \n",
    "    return D\n",
    "\n",
    "#builds the feature vector for sequence using specified indexing dictionary\n",
    "def FeatureVector(dictionary, sequence, n):    \n",
    "    sLen = len(sequence)\n",
    "    arr = [0]*4**n\n",
    "    i = 0\n",
    "    \n",
    "    while(1):\n",
    "        w = sequence[i:i+n]\n",
    "        try:\n",
    "            arr[D[w]] += 1\n",
    "        except:\n",
    "            i = i\n",
    "        i += 1\n",
    "        if(i+n > sLen):\n",
    "            break\n",
    "    \n",
    "    return arr\n",
    "\n",
    "#Reads the DB files and puts the information of the file in a array of strings\n",
    "def readfile(filename):\n",
    "    temp = open(filename, 'r').read().split('\\n')\n",
    "    return temp\n",
    "    \n",
    "    \n",
    "#returns a random string of specified length\n",
    "#length: strign length\n",
    "def randomword(length):\n",
    "    return (''.join(choice('ACGT') for i in range(0, length)))\n",
    "\n",
    "#retuns an array of random strings\n",
    "#size: how many strings there will be in the array\n",
    "#lakeMinLen: min sequence length\n",
    "#lakeMaxLen: max sequence length\n",
    "def lakeString(size, lakeMinLen, lakeMaxLen):     \n",
    "    lake_water = []\n",
    "    for i in range(0, size):\n",
    "        random.seed()\n",
    "        #generates a random sequence length\n",
    "        y = random.randint(lakeMinLen, lakeMaxLen)\n",
    "        \n",
    "        _str = randomword(y)\n",
    "        lake_water.append(_str)\n",
    "    return lake_water\n",
    "\n",
    "def readTxtFile(filename):\n",
    "    data = []\n",
    "    fid = open(filename,'r')\n",
    "    for line in fid:\n",
    "        data.append(line)\n",
    "    return data\n",
    "        \n",
    "\n",
    "# ******************************************************* main ****************************************************\n",
    "\n",
    "use_pca = False\n",
    "pca_components = 2\n",
    "\n",
    "print(\"reading viruses...\")\n",
    "known_viruses = ReadDataBase(\"../database/virus/\", 200)\n",
    "print(\"reading bacterias...\")\n",
    "known_bacterias = ReadDataBase(\"../database/bact/\", 200)\n",
    "print(\"reading lake samples...\")\n",
    "\n",
    "# lake = ReadDataBase(\"../database/lake/\", 50)\n",
    "lake = readfile(\"../database/lake.txt\") \n",
    "\n",
    "print(\"finished reading data\")\n",
    "\n",
    "#matrix with all feature vectors\n",
    "n = 4\n",
    "D = CreateDictionary(n)\n",
    "lake_matrix = []\n",
    "virus_matrix = []\n",
    "bact_matrix = []\n",
    "\n",
    "m = 0\n",
    "print(\"feature vector lake...\")\n",
    "for w in lake:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    m+=1\n",
    "    if(m%50 == 0):\n",
    "        print(m,\"of\", len(lake))\n",
    "    lake_matrix.append(arr)\n",
    "\n",
    "m=0\n",
    "print(\"feature vector virus...\")\n",
    "for w in known_viruses:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    m+=1\n",
    "    if(m%50 == 0):\n",
    "        print(m,\"of\", len(known_viruses))\n",
    "    virus_matrix.append(arr)\n",
    "\n",
    "m=0\n",
    "print(\"feature vector bacteria...\")\n",
    "for w in known_bacterias:\n",
    "    arr = FeatureVector(D, str(w), n)\n",
    "    arr = np.divide(np.array(arr), len(w))\n",
    "    m+=1\n",
    "    if(m%50 == 0):\n",
    "        print(m,\"of\", len(known_bacterias))\n",
    "    bact_matrix.append(arr)\n",
    "\n",
    "len_lake = len(lake)\n",
    "len_viruses = len(known_viruses)\n",
    "    \n",
    "print(\"lake shape: \", np.matrix(lake_matrix).shape)\n",
    "print(\"virus shape: \", np.matrix(virus_matrix).shape)\n",
    "print(\"bacteria shape: \", np.matrix(bact_matrix).shape)\n",
    "\n",
    "matrix = np.vstack((virus_matrix,bact_matrix))\n",
    "\n",
    "\n",
    "### PCA\n",
    "if use_pca:\n",
    "    X = np.array(matrix)\n",
    "    # PCA input: samples x features\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    Xhat = pca.fit_transform(X)\n",
    "    print(\"Percentage of represented variance: \", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "    data = np.transpose(Xhat)\n",
    "    data_virus = data[:, :len_viruses]\n",
    "    data_bact = data[:,len_viruses:]\n",
    "\n",
    "#     ####### Plot results\n",
    "#     if pca_components == 2:\n",
    "#         plt.plot(data_virus[0], data_virus[1], 'go')\n",
    "#         plt.plot(data_bact[0], data_bact[1], 'ro')\n",
    "#     elif pca_components == 3:\n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "#         ax.scatter(data_virus[0], data_virus[1], data_virus[2], c='g', depthshade=False)\n",
    "#         ax.scatter(data_bact[0], data_bact[1], data_bact[2], c='r', depthshade=False)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#### K MEANS CLUSTERING\n",
    "if use_pca:\n",
    "    data = np.array(Xhat)\n",
    "else:\n",
    "    data = np.array(matrix)\n",
    "    \n",
    "# training\n",
    "num_clusters = 12\n",
    "estimator = KMeans(n_clusters=num_clusters)\n",
    "estimator.fit(data)\n",
    "training_labels = estimator.labels_\n",
    "\n",
    "clusters = [[]]*num_clusters  # stores the index of the points in each cluster\n",
    "for clust in range(0,num_clusters):\n",
    "    labels_idx = np.where(training_labels == clust)[0]\n",
    "    clusters[clust] = labels_idx\n",
    "\n",
    "# printing cluster data\n",
    "i = 0\n",
    "for clt in clusters:\n",
    "    virs = [c for c in clt if c < len_viruses]\n",
    "    perc = len(virs)/len(clt)\n",
    "    print(\"% of virus in cluster \", i, \": \", perc)\n",
    "    i += 1\n",
    "    \n",
    "# testing\n",
    "if use_pca:\n",
    "    lake_matrix = pca.transform(lake_matrix)\n",
    "estimated_labels = estimator.predict(lake_matrix)\n",
    "\n",
    "right = 0\n",
    "cnt_lbl = 0\n",
    "for lbl in estimated_labels:\n",
    "    labels_idx = np.where(training_labels == lbl)[0]\n",
    "    cnt_virus = 0\n",
    "    cnt_bact = 0\n",
    "    for lblidx in labels_idx:\n",
    "        if lblidx < len_viruses:\n",
    "            cnt_virus += 1\n",
    "        else:\n",
    "            cnt_bact += 1\n",
    "    if cnt_virus > cnt_bact and cnt_lbl < 100: # 100 for that sample\n",
    "        right += 1\n",
    "    if cnt_bact > cnt_virus and cnt_lbl >= 100:\n",
    "        right += 1\n",
    "    cnt_lbl += 1\n",
    "\n",
    "print (\"\\nAccuraccy: \", right/len_lake)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_trans = np.transpose(data)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# for i in range(len(data_in)):\n",
    "#     if i < len_viruses:\n",
    "#         if labels[i] == 0:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='y', marker='o', depthshade=False)\n",
    "#         elif labels[i] == 1:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='y', marker='^', depthshade=False)\n",
    "#     elif i >= len_viruses:\n",
    "#         if labels[i] == 0:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='b', marker='o', depthshade=False)\n",
    "#         elif labels[i] == 1:\n",
    "#             ax.scatter(data_trans[0,i], data_trans[1,i], data_trans[2,i], c='b', marker='^', depthshade=False)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('myfig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
